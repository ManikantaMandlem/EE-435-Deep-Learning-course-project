{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManikantaMandlem/EE-435-Deep-Learning-course-project/blob/main/DLFAA_project_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYieWoH-emDD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD4bPGi-ebLW"
      },
      "source": [
        "Collate function is not working, start from here 21-02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKfWZm9YLTw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7BAFppCVMwN"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'batchsize' : 64,\n",
        "    'shuffle' : True,\n",
        "    'num_workers' : 8,\n",
        "    'lr' : 0.0001,\n",
        "    'epochs' : 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4on0vBj83fL"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "F32S-8ABypAi",
        "outputId": "88940c2f-7500-45bc-98cf-7118fd7efe55"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 135\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwaha3gkYEaz"
      },
      "source": [
        "threshold = 5\n",
        "\n",
        "min_images = 2\n",
        "\n",
        "os.walk(filter for folders more than threshold)\n",
        "\n",
        "create train, valid1, valid2, test1 and test2\n",
        "\n",
        "1 - people that are already seen by model\n",
        "\n",
        "2 - people that are not seen by model\n",
        "\n",
        "to create 1, move first min_images of a person to train and the rest is assigned randomly with probabilities of 90-5-5 to valid1 and test1\n",
        "\n",
        "for 2, split the test dataset into to build valid2 and test2\n",
        "create dataset objects for all 5 and create dataloads for all 5\n",
        "\n",
        "Download and save resnet model, change the fully connected layer (add fully connected layers if necessary)\n",
        "\n",
        "Train, validate and test the model....hooray..! :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB6kyVtIYZZu"
      },
      "outputs": [],
      "source": [
        "person_dir = []\n",
        "person_img_path = defaultdict(list)\n",
        "threshold = 4\n",
        "# imagesplit_thr = 2\n",
        "mypath = '/content/drive/MyDrive/DLFAA/Final_Project/lfw'\n",
        "dirnames = os.listdir(mypath)\n",
        "dirnames.pop(5000)\n",
        "for dirname in dirnames:\n",
        "    path = mypath +'/'+ dirname\n",
        "    person_img_path[path] = os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrIfwqA6e5x9"
      },
      "outputs": [],
      "source": [
        "type1_dict = defaultdict(list)\n",
        "type2_dict = defaultdict(list)\n",
        "\n",
        "file1 = open('/content/drive/MyDrive/DLFAA/Final_Project/train.txt', 'r')\n",
        "file2 = open('/content/drive/MyDrive/DLFAA/Final_Project/test.txt', 'r')\n",
        "\n",
        "for line in file1:\n",
        "    type1_dict[mypath +'/' + line.strip()] = person_img_path[mypath +'/' + line.strip()]\n",
        "for line in file2:\n",
        "    type2_dict[mypath +'/' + line.strip()] = person_img_path[mypath +'/' + line.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usryTU4EXJZq"
      },
      "outputs": [],
      "source": [
        "print(mypath + '/'+'Leszek_Miller')\n",
        "print(type1_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9rcQQA7gFEu"
      },
      "outputs": [],
      "source": [
        "print(len(type1_dict))\n",
        "del_list = []\n",
        "for names in type1_dict.keys():\n",
        "    if len(type1_dict[names]) < threshold:\n",
        "        del_list.append(names)\n",
        "for name in del_list:\n",
        "    del type1_dict[name]\n",
        "print(len(del_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2HZwBHyhV4W"
      },
      "outputs": [],
      "source": [
        "type2_val = defaultdict(list)\n",
        "type2_test = defaultdict(list)\n",
        "\n",
        "for name in type2_dict.keys():\n",
        "    size = len(type2_dict[name])\n",
        "    if len(type2_dict[name]) >= 2:\n",
        "        type2_val[name].extend(type2_dict[name][:size//2]) # 7  -  0, 3\n",
        "        type2_test[name].extend(type2_dict[name][size//2 : size - size%2]) # 3, 6\n",
        "    if size % 2:\n",
        "        if np.random.rand() < 0.5:\n",
        "            type2_val[name].append(type2_dict[name][-1])\n",
        "        else:\n",
        "            type2_test[name].append(type2_dict[name][-1])\n",
        "# print(type2_dict)\n",
        "# print(type2_val)\n",
        "# print(type2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML8V9rsUj4iy"
      },
      "outputs": [],
      "source": [
        "train = defaultdict(list)\n",
        "type1_val = defaultdict(list)\n",
        "type1_test = defaultdict(list)\n",
        "\n",
        "for name in type1_dict.keys():\n",
        "    size = len(type1_dict[name])\n",
        "    #if size > imagesplit_thr:\n",
        "    train[name] = type1_dict[name][:int(size*0.8)]\n",
        "    size2 = size - int(size*0.8)\n",
        "    #for image in type1_dict[name][size*0.8:]:\n",
        "    if size2 >= 2:\n",
        "        type1_val[name].extend(type1_dict[name][int(size*0.8):int(size*0.8)+size2//2]) \n",
        "        type1_test[name].extend(type1_dict[name][int(size*0.8)+size2//2 : size - size2%2])\n",
        "    if size2 % 2:\n",
        "        if np.random.rand() < 0.5:\n",
        "            type1_val[name].append(type1_dict[name][-1])\n",
        "        else:\n",
        "            type1_test[name].append(type1_dict[name][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YllMbbYIjFjN"
      },
      "outputs": [],
      "source": [
        "person_mapping = {}\n",
        "i = 0\n",
        "for path in train:\n",
        "    person_mapping[path.split('/')[-1]] = i\n",
        "    i+=1\n",
        "for path in type2_val:\n",
        "    person_mapping[path.split('/')[-1]] = i\n",
        "    i+=1\n",
        "for path in type2_test:\n",
        "    person_mapping[path.split('/')[-1]] = i\n",
        "    i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWPFn1I-qiDm"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset):\n",
        "    data = []\n",
        "    for path in dataset:\n",
        "        for image in dataset[path]:\n",
        "            data.append([path+'/'+image,person_mapping[path.split('/')[-1]]])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m31CXaturZtA"
      },
      "outputs": [],
      "source": [
        "data_train_todataset = get_data(train)\n",
        "print(len(data_train_todataset))\n",
        "\n",
        "data_val1_todataset = get_data(type1_val)\n",
        "print(len(data_val1_todataset))\n",
        "\n",
        "data_val2_todataset = get_data(type2_val)\n",
        "print(len(data_val2_todataset))\n",
        "\n",
        "data_test1_todataset = get_data(type1_test)\n",
        "print(len(data_test1_todataset))\n",
        "\n",
        "data_test2_todataset = get_data(type2_test)\n",
        "print(len(data_test2_todataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrpsL1fetsJt"
      },
      "outputs": [],
      "source": [
        "def read_image(path):\n",
        "    return torchvision.io.read_image(path)\n",
        "image = read_image('/content/drive/MyDrive/DLFAA/Final_Project/lfw/Ahmed_Chalabi/Ahmed_Chalabi_0001.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9j3Vrj4QqH4"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                             transforms.RandomVerticalFlip(p=0.5),\n",
        "                                             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WK1q1_cRwk7"
      },
      "outputs": [],
      "source": [
        "img1 = read_image('/content/drive/MyDrive/DLFAA/Final_Project/lfw/Ahmed_Chalabi/Ahmed_Chalabi_0001.jpg')\n",
        "img2 = read_image('/content/drive/MyDrive/DLFAA/Final_Project/lfw/Ahmed_Chalabi/Ahmed_Chalabi_0001.jpg')\n",
        "concat = torch.cat([img1,img2],dim = 1)\n",
        "print(concat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekMw7BDiiTRs"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, data_dict, transform):\n",
        "        self.data = data\n",
        "        self.data_dict = data_dict\n",
        "        self.length = len(data)\n",
        "        self.transform_flag = transform\n",
        "        self.transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5), \n",
        "                                             transforms.RandomVerticalFlip(p=0.5)\n",
        "                                             ]) ###is this helpful\n",
        "                                            #  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "                                             ###add more tranformations\n",
        "        self.normalize = transforms.Compose([transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        anchor = read_image(self.data[index][0])\n",
        "        anchor = anchor.float()/255\n",
        "        negative = random.choice(range(self.length))\n",
        "        while self.data[negative][1] == self.data[index][1]:\n",
        "            negative = random.choice(range(self.length))\n",
        "        negative = read_image(self.data[negative][0])\n",
        "        negative = negative.float()/255\n",
        "\n",
        "        positive_key = '/'.join(self.data[index][0].split('/')[:-1])\n",
        "        positive = random.choice(self.data_dict[positive_key])\n",
        "        positive = read_image(positive_key + '/' + positive)\n",
        "        positive = positive.float()/255\n",
        "\n",
        "        if self.transform_flag:\n",
        "            anchor = self.transform(anchor) ###may try removing transform for anchor and negative and try\n",
        "            negative = self.transform(negative)\n",
        "            positive = self.transform(positive)\n",
        "        anchor = self.normalize(anchor) \n",
        "        negative = self.normalize(negative)\n",
        "        positive = self.normalize(positive)\n",
        "        pos_example = torch.cat([anchor,positive],dim=1)\n",
        "        neg_example = torch.cat([anchor,negative],dim=1)\n",
        "        return torch.stack([pos_example,neg_example],dim=3)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPXSOVXyT8oH"
      },
      "outputs": [],
      "source": [
        "def collate_fn(data):\n",
        "    data = torch.stack(data)\n",
        "    length = data.shape[0]\n",
        "    data = torch.cat([data[:,:,:,:,0],data[:,:,:,:,1]])\n",
        "    labels = torch.cat([torch.ones(length),torch.zeros(length)])\n",
        "    idx = torch.randperm(2*length)\n",
        "    data = data[idx]\n",
        "    labels = labels[idx]\n",
        "    return data, labels\n",
        "\n",
        "training_data = DataLoader(Dataset(data_train_todataset, train, True), \n",
        "                           params['batchsize'], \n",
        "                           params['shuffle'], \n",
        "                           collate_fn = collate_fn, \n",
        "                           num_workers=params['num_workers'])\n",
        "\n",
        "val1_data = DataLoader(Dataset(data_val1_todataset, type1_val, False), \n",
        "                           params['batchsize'], \n",
        "                           params['shuffle'], \n",
        "                           collate_fn = collate_fn, \n",
        "                           num_workers=params['num_workers'])\n",
        "\n",
        "val2_data = DataLoader(Dataset(data_val2_todataset, type2_val, False), \n",
        "                           params['batchsize'], \n",
        "                           params['shuffle'], \n",
        "                           collate_fn = collate_fn, \n",
        "                           num_workers=params['num_workers'])\n",
        "\n",
        "test1_data = DataLoader(Dataset(data_test1_todataset, type1_test, False), \n",
        "                           params['batchsize'], \n",
        "                           params['shuffle'], \n",
        "                           collate_fn = collate_fn, \n",
        "                           num_workers=params['num_workers'])\n",
        "\n",
        "test2_data = DataLoader(Dataset(data_test2_todataset, type2_test, False), \n",
        "                           params['batchsize'], \n",
        "                           params['shuffle'], \n",
        "                           collate_fn = collate_fn, \n",
        "                           num_workers=params['num_workers'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPR0o2JJCen1"
      },
      "outputs": [],
      "source": [
        "\"\"\"for data,label in training_data:\n",
        "    print(data.shape)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNdLbemPWN_a"
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = nn.Sequential(\n",
        "    model_ft,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1000, 2)\n",
        ")\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ft.parameters(), params['lr'])\n",
        "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnlWLe0rCd4L"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQCEJImJY5bN"
      },
      "outputs": [],
      "source": [
        "#summary(model_ft,(3,500,250))\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjpQZwRk9wry"
      },
      "outputs": [],
      "source": [
        "results_loss = defaultdict()\n",
        "results_acc = defaultdict()\n",
        "results_loss['train'] = []\n",
        "results_acc['train'] = []\n",
        "\n",
        "results_loss['val1'] = []\n",
        "results_acc['val1'] = []\n",
        "\n",
        "results_loss['val2'] = []\n",
        "results_acc['val2'] = []\n",
        "\n",
        "for epoch in range(params['epochs']):\n",
        "    model_ft.train()\n",
        "    running_loss = 0.0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, x in enumerate(training_data, 0):\n",
        "        batch_count += 1\n",
        "        inputs, labels = x\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_ft(inputs)\n",
        "        loss = criterion(outputs,labels)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # print(\"Epoch\", epoch+1, \"Batch:\", batch_count, \"Loss\", loss.item(), \"accuracy\", (predicted == labels).sum().item()/labels.size(0))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print('Accuracy of train images: {}'.format(correct / total))\n",
        "    print(\"E:{}, Train Loss:{}\".format(epoch+1, running_loss / batch_count))\n",
        "\n",
        "    results_loss['train'].append(running_loss / batch_count)\n",
        "    results_acc['train'].append(correct / total)\n",
        "\n",
        "    #validation1\n",
        "    model_ft.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "    batch_count = 0\n",
        "    with torch.no_grad():\n",
        "        for data in val1_data:\n",
        "\n",
        "            batch_count+=1\n",
        "            images,labels = data\n",
        "            labels=labels.type(torch.LongTensor)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_ft(images)  \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "                \n",
        "            loss = criterion(outputs, labels)       \n",
        "            val_loss += loss.item()\n",
        "    val_loss /= batch_count\n",
        "    print('Epoch {} Accuracy of val1 images: {}'.format(epoch+1,  correct / total))\n",
        "    print('Epoch {} Val1 Loss: {}'.format(epoch+1, val_loss))\n",
        "\n",
        "    results_loss['val1'].append(val_loss)\n",
        "    results_acc['val1'].append(correct / total)\n",
        "\n",
        "    #validation2\n",
        "    model_ft.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "    batch_count = 0\n",
        "    with torch.no_grad():\n",
        "        for data in val2_data:\n",
        "\n",
        "            batch_count+=1\n",
        "            images, labels = data\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_ft(images)  \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "                \n",
        "            loss = criterion(outputs,labels)       \n",
        "            val_loss += loss.item()\n",
        "    val_loss /= batch_count\n",
        "    print('Epoch {} Accuracy of val2 images: {}'.format(epoch+1,  correct / total))\n",
        "    print('Epoch {} Val2 Loss: {}'.format(epoch+1, val_loss))\n",
        "\n",
        "    results_loss['val2'].append(val_loss)\n",
        "    results_acc['val2'].append(correct / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmIMbNN-H8bb"
      },
      "outputs": [],
      "source": [
        "print(results_loss)\n",
        "print(results_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/DLFAA/Final_Project/base_results.txt','a') as data: \n",
        "    data.write('Loss\\n')\n",
        "    data.write(str(results_loss))\n",
        "    data.write('\\nAccuracy\\n')\n",
        "    data.write(str(results_acc))"
      ],
      "metadata": {
        "id": "PaxXiauhuSYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "val_loss = 0.0\n",
        "batch_count = 0\n",
        "with torch.no_grad():\n",
        "    for data in test1_data:\n",
        "        batch_count+=1\n",
        "        images, labels = data\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_ft(images)  \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item() \n",
        "        loss = criterion(outputs,labels)       \n",
        "        val_loss += loss.item()\n",
        "val_loss /= batch_count\n",
        "print('Accuracy of test1 images: {}'.format(  correct / total))\n",
        "print('test1 Loss: {}'.format( val_loss))"
      ],
      "metadata": {
        "id": "mtktzJhKYdvJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DLFAA_project_master",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}